using GeoStats
using SpectralGaussianSimulation
using DensityRatioEstimation
using CategoricalArrays
using LossFunctions
using ProgressMeter
using DataFrames
using MLJ, CSV
using LinearAlgebra
using Random

# reproducible results
Random.seed!(123)

# generate random images with given spatial mean, range and sill
function generator(nimgs=1; mean=0., range=1., sill=1., size=(100,100))
  Œ≥ = GaussianVariogram(range=range, sill=sill)
  p = SimulationProblem(RegularGrid{Float64}(size), (:Z1=>Float64,:Z2=>Float64), nimgs)
  s = SpecGaussSim(:Z1=>(mean=mean, variogram=Œ≥), :Z2=>(mean=mean, variogram=Œ≥))
  solve(p, s)
end

# generate a covariate shift configuration with given Œ¥ and œÑ
function covariateshift(Œ¥, œÑ, r; ns=1, nt=1, size=(100,100))
  Œº‚ÇÅ, œÉ‚ÇÅ = 0.0, 1.0
  Œº‚ÇÇ, œÉ‚ÇÇ = 3*‚àö2*œÉ‚ÇÅ*Œ¥, œÑ*œÉ‚ÇÅ
  simgs = generator(ns, mean=Œº‚ÇÅ, sill=œÉ‚ÇÅ^2, range=r, size=size)
  timgs = generator(nt, mean=Œº‚ÇÇ, sill=œÉ‚ÇÇ^2, range=r, size=size)
  simgs, timgs
end

# geostatistical learning problem with given covariate shift configuration
function problem(; Œ¥=0.0, œÑ=1.0, r=10.0, size=(100,100))
  # covariate shift
  simgs, timgs = covariateshift(Œ¥, œÑ, r, nt=101, size=size)

  # sine-norm labeling function
  label(z, p=1) = sin(4*norm(z, p)) < 0 ? 1 : 0
  f(Œì) = georef(OrderedDict(:LABEL => categorical([label(z) for z in view(Œì, [:Z1,:Z2])])), domain(Œì))

  # add labels to all samples
  Œ©ss = [join(Œ©, f(Œ©)) for Œ© in simgs]
  Œ©ts = [join(Œ©, f(Œ©)) for Œ© in timgs]

  # geostatistical learning problem
  p = LearningProblem(Œ©ss[1], Œ©ts[1], ClassificationTask((:Z1,:Z2), :LABEL))

  # return problem and other Œ©t samples
  p, Œ©ts[2:end]
end

# estimators of generalization error
error_cv(m, p, k) = error(PointwiseLearn(m), p, CrossValidation(k))
error_bv(m, p, r) = error(PointwiseLearn(m), p, BlockCrossValidation(r))
error_dr(m, p, k) = error(PointwiseLearn(m), p, DensityRatioValidation(k,estimator=LSIF(œÉ=2.0,b=10)))

# true error (empirical approximation)
function error_empirical(m, p, Œ©ts)
  # train on source data
  l = GeoStats.learn(task(p), sourcedata(p), m)

  # test on various samples of target data
  es = map(Œ©ts) do Œ©t
    y = vec(Œ©t[:LABEL])
    ≈∑ = vec(perform(task(p), Œ©t, l)[:LABEL])
    ùîè = MisclassLoss()
    LossFunctions.value(ùîè, y, ≈∑, AggMode.Mean())
  end

  # averate misclassification rate
  mean(es)
end

function error_comparison(m, Œ¥, œÑ, r)
  # sample a problem
  p, Œ©ts = problem(Œ¥=Œ¥, œÑ=œÑ, r=r)

  # parameters for validation methods
  r·µ¶ = 20.
  s  = size(sourcedata(p))
  k  = round(Int, prod(s ./ r·µ¶))

  # try different error estimates
  cv = error_cv(m, p, k)[:LABEL]
  bv = error_bv(m, p, r·µ¶)[:LABEL]
  dr = error_dr(m, p, k)[:LABEL]

  # actual error (empirical estimate)
  actual = error_empirical(m, p, Œ©ts)

  (Œ¥=Œ¥, œÑ=œÑ, r=r, CV=cv, BV=bv, DR=dr, ACTUAL=actual, MODEL=info(m).name)
end

# -------------
# MAIN SCRIPT
# -------------

# learning models
@load KNNClassifier
@load DecisionTreeClassifier

# parameter ranges
Œ¥range = 0.0:0.1:0.7
œÑrange = 0.5:0.1:1.0
rrange = [1e-4,1e+1,2e+1]
mrange = [DecisionTreeClassifier(),KNNClassifier()]

results = DataFrame()
@showprogress for m in mrange, Œ¥ in Œ¥range, œÑ in œÑrange, r in rrange
  try
    push!(results, error_comparison(m, Œ¥, œÑ, r))
  catch e
    println("Skipped m=$m Œ¥=$Œ¥ œÑ=$œÑ r=$r")
  end
end

CSV.write("results/gaussian.csv", results)
