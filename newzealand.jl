using Pkg; Pkg.instantiate()

using GeoStats
using DensityRatioEstimation
using LossFunctions
using ProgressMeter
using DataFrames
using DataDeps
using MLJ, CSV
using Statistics
using Random

# download dataset if needed
register(DataDep("NewZealand",
         "Taranaki Basin Curated Well Logs",
         "https://dax-cdn.cdn.appdomain.cloud/dax-taranaki-basin-curated-well-logs/1.0.0/taranaki-basin-curated-well-logs.tar.gz",
         "608f7aad5a4e9fded6441fd44f242382544d3f61790446175f5ede83f15f4d11",
         post_fetch_method=unpack))

# name of the CSV file in the dataset
csv = joinpath(datadep"NewZealand","taranaki-basin-curated-well-logs","logs.csv")

# reproducible results
Random.seed!(2020)

# estimators of generalization error
error_cv( m, p, k, â„’) = error(PointwiseLearn(m), p, CrossValidation(k, loss=â„’))
error_bcv(m, p, r, â„’) = error(PointwiseLearn(m), p, BlockCrossValidation(r, loss=â„’))
error_drv(m, p, k, â„’) = error(PointwiseLearn(m), p, DensityRatioValidation(k, loss=â„’, estimator=LSIF(Ïƒ=2.0,b=10)))

# true error (known labels)
function error_empirical(m, p, â„’)
  results = map(outputvars(task(p))) do var
    y = targetdata(p)[var]
    Å· = solve(p, PointwiseLearn(m))[var]
    var => LossFunctions.value(â„’[var], y, yÌ‚, AggMode.Mean())
  end
  Dict(results)
end

function experiment(m, p, r, k, â„’)
    # try different error estimates
    cv  = error_cv( m, p, k, â„’)
    bcv = error_bcv(m, p, r, â„’)
    drv = error_drv(m, p, k, â„’)

    # actual error (unhide labels)
    actual = error_empirical(m, p, â„’)

    map(outputvars(task(p))) do var
      (CV=cv[var], BCV=bcv[var], DRV=drv[var],
       ACTUAL=actual[var], MODEL=info(m).name, TARGET=var)
    end
end

# -------------
# MAIN SCRIPT
# -------------

# logs used in the experiment
logs = [:GR,:SP,:DENS,:NEUT,:DTC]

# read/clean raw data
df = CSV.read(csv)
df = df[:,[logs...,:X,:Y,:Z,:FORMATION,:ONSHORE]]
dropmissing!(df)
categorical!(df, :FORMATION)
categorical!(df, :ONSHORE)
for log in logs
  x = df[!,log]
  Î¼ = mean(x)
  Ïƒ = std(x, mean=Î¼)
  df[!,log] .= (x .- Î¼) ./ Ïƒ
end

# define spatial data
wells = GeoDataFrame(df, [:X,:Y,:Z])

# select the two most frequent formations
formations = groupby(wells, :FORMATION)
frequency = sortperm(npoints.(formations), rev=true)
ð’ž = DataCollection(formations[frequency[1:2]])

# eliminate duplicate coordinates
Î© = uniquecoords(ð’ž)

# split onshore (True) vs. offshore (False)
onoff = groupby(Î©, :ONSHORE)
order = sortperm(onoff[:values], rev=true)
Î©s, Î©t = onoff[order]

# set block sides and equivalent number of folds
r = (10000.,10000.,500.)
k = length(GeoStats.partition(Î©s, BlockPartitioner(r)))

# ---------------
# CLASSIFICATION
# ---------------
@load LDA pkg="MultivariateStats"
@load KNNClassifier pkg="NearestNeighbors"
@load EvoTreeClassifier pkg="EvoTrees"
@load GaussianNBClassifier pkg="NaiveBayes"

# parameter ranges
mrange = [LDA(), ConstantClassifier(), KNNClassifier(),
          EvoTreeClassifier(), GaussianNBClassifier()]

# experiment iterator and progress
iterator = Iterators.product(mrange)
progress = Progress(length(iterator), "New Zealand classification:")

# return missing in case of failure
skip = e -> (println("Skipped: $e"); missing)

# perform experiments
cresults = progress_pmap(iterator, progress=progress,
                         on_error=skip) do (m,)
  t = ClassificationTask(logs, :FORMATION)
  p = LearningProblem(Î©s, Î©t, t)
  â„’ = Dict(:FORMATION => MisclassLoss())
  experiment(m, p, r, k, â„’)
end

# -----------
# REGRESSION
# -----------
@load KNNRegressor pkg="NearestNeighbors"
@load DecisionTreeRegressor pkg="DecisionTree"

# parameter ranges
mrange = [ConstantRegressor(), KNNRegressor(), DecisionTreeRegressor()]
vrange = logs

# experiment iterator and progress
iterator = Iterators.product(mrange, vrange)
progress = Progress(length(iterator), "New Zealand regression:")

# perform experiments
rresults = progress_pmap(iterator, progress=progress,
                         on_error=skip) do (m, v)
  t = RegressionTask(logs[logs .!= v], v)
  p = LearningProblem(Î©s, Î©t, t)
  â„’ = Dict(v => L2DistLoss())
  experiment(m, p, r, k, â„’)
end

# merge all results into dataframe
allres = vcat(cresults[:], rresults[:])
resdf = DataFrame(Iterators.flatten(skipmissing(allres)))

# save all results to disk
fname = joinpath(@__DIR__,"results","newzealand.csv")
CSV.write(fname, resdf)
